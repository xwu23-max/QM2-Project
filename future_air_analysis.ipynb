{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92e495b",
   "metadata": {},
   "source": [
    "# Future Air (LAEI 2025–2030) — Reproducible Notebook\n",
    "This notebook reproduces the figures and outputs used in the Future Air section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef979df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install pandas numpy matplotlib plotly openpyxl requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Future Air (LAEI 2025–2030) — Reproducible Analysis Script\n",
    "---------------------------------------------------------\n",
    "Generates:\n",
    "- Figure 1: headline scorecard (PNG)\n",
    "- Figure 2a/2b: interactive choropleth maps (HTML)\n",
    "- Figure 3: Top/Bottom 5 extremes table (PNG)\n",
    "- Figure 4: Inner vs Outer mean % change (PNG)\n",
    "- Figure 5: PM2.5 mechanism split (PNG)\n",
    "- Clean output dataset (CSV)\n",
    "\n",
    "Inputs:\n",
    "- Extracted Data 2025&2030.xlsx  (your extracted LAEI tables)\n",
    "- boroughs_london.geojson (London borough polygons)\n",
    "\n",
    "If boroughs_london.geojson is missing, the script can download it\n",
    "from Westminster Data Studio's open_data repository.\n",
    "\n",
    "How to run:\n",
    "    python future_air_analysis.py\n",
    "\n",
    "Recommended environment:\n",
    "    pip install pandas numpy matplotlib plotly openpyxl requests\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIG (edit these paths)\n",
    "# ---------------------------\n",
    "INPUT_EXCEL = os.path.join(\"data\", \"Extracted Data 2025&2030.xlsx\")\n",
    "\n",
    "# Put the GeoJSON here (or let the script download it)\n",
    "BOROUGHS_GEOJSON = os.path.join(\"data\", \"boroughs_london.geojson\")\n",
    "\n",
    "# Where outputs will be written\n",
    "OUT_DIR = os.path.join(\"outputs\", \"future_air_figs\")\n",
    "\n",
    "# Download URL for GeoJSON (Westminster Data Studio)\n",
    "# Source page: https://www.londondata.studio/data/boundary-files/\n",
    "BOROUGHS_GEOJSON_URL = (\n",
    "    \"https://raw.githubusercontent.com/westminsterDataStudio/open_data/main/\"\n",
    "    \"boundary_files/boroughs_london.geojson\"\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def ensure_geojson(path: str, url: str) -> None:\n",
    "    \"\"\"Download borough GeoJSON if it does not exist.\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    import requests\n",
    "\n",
    "    print(f\"[INFO] Downloading borough GeoJSON → {path}\")\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "def parse_sheet(path: str, sheet_name: str) -> tuple[pd.DataFrame, list[str]]:\n",
    "    \"\"\"\n",
    "    Read the Excel sheet and detect the header row where column B equals 'Source'.\n",
    "    Returns:\n",
    "        df: cleaned dataframe with a 'Source' column and borough columns\n",
    "        borough_cols: list of borough column names\n",
    "    \"\"\"\n",
    "    raw = pd.read_excel(path, sheet_name=sheet_name, header=None)\n",
    "\n",
    "    header_row_idx = None\n",
    "    for i in range(len(raw)):\n",
    "        if raw.iloc[i, 1] == \"Source\":\n",
    "            header_row_idx = i\n",
    "            break\n",
    "    if header_row_idx is None:\n",
    "        raise ValueError(f\"Could not detect header row in sheet: {sheet_name}\")\n",
    "\n",
    "    header = raw.iloc[header_row_idx].tolist()\n",
    "    df = raw.iloc[header_row_idx + 1 :].copy()\n",
    "    df.columns = header\n",
    "    df = df[df[\"Source\"].notna()].copy()\n",
    "\n",
    "    exclude = {\n",
    "        \"Source\",\n",
    "        \"Central London\",\n",
    "        \"Inner London\",\n",
    "        \"Outer London\",\n",
    "        \"Non-GLA\",\n",
    "        \"总计\",\n",
    "        \"行标签\",\n",
    "    }\n",
    "    borough_cols = [\n",
    "        c for c in df.columns if isinstance(c, str) and c not in exclude\n",
    "    ]\n",
    "\n",
    "    # Coerce numeric columns\n",
    "    for c in borough_cols + [\"Central London\", \"Inner London\", \"Outer London\", \"Non-GLA\", \"总计\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df, borough_cols\n",
    "\n",
    "def extract_borough_values(df: pd.DataFrame, borough_cols: list[str], source_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Extract borough values for one LAEI 'Source' row.\"\"\"\n",
    "    sub = df[df[\"Source\"] == source_name]\n",
    "    if sub.empty:\n",
    "        raise ValueError(f\"Source '{source_name}' not found. Available sources: {df['Source'].unique()[:10]} ...\")\n",
    "    row = sub.iloc[0]\n",
    "    vals = row[borough_cols].astype(float)\n",
    "    return pd.DataFrame({\"borough\": borough_cols, \"value\": vals.values})\n",
    "\n",
    "def merge_years(df25: pd.DataFrame, df30: pd.DataFrame, label: str) -> pd.DataFrame:\n",
    "    \"\"\"Merge 2025 vs 2030 borough values and compute changes.\"\"\"\n",
    "    m = df25.merge(df30, on=\"borough\", suffixes=(\"_2025\", \"_2030\"))\n",
    "    m[\"abs_change\"] = m[\"value_2030\"] - m[\"value_2025\"]\n",
    "    m[\"pct_change\"] = np.where(m[\"value_2025\"] != 0, m[\"abs_change\"] / m[\"value_2025\"] * 100, np.nan)\n",
    "    m[\"metric\"] = label\n",
    "    return m\n",
    "\n",
    "def totals(df25: pd.DataFrame, df30: pd.DataFrame, source_name: str) -> tuple[float, float, float, float]:\n",
    "    \"\"\"London total ('总计') for one source in 2025 vs 2030.\"\"\"\n",
    "    r25 = df25[df25[\"Source\"] == source_name].iloc[0]\n",
    "    r30 = df30[df30[\"Source\"] == source_name].iloc[0]\n",
    "    total25 = float(r25[\"总计\"])\n",
    "    total30 = float(r30[\"总计\"])\n",
    "    abs_change = total30 - total25\n",
    "    pct_change = abs_change / total25 * 100 if total25 else np.nan\n",
    "    return total25, total30, abs_change, pct_change\n",
    "\n",
    "def to_geo_name(b: str) -> str:\n",
    "    \"\"\"Match borough naming between LAEI extract and GeoJSON.\"\"\"\n",
    "    if b == \"Kingston\":\n",
    "        return \"Kingston upon Thames\"\n",
    "    if b == \"Richmond\":\n",
    "        return \"Richmond upon Thames\"\n",
    "    return b\n",
    "\n",
    "# London Plan (2021) Annex 2: Inner/Outer boroughs\n",
    "INNER_BOROUGHS = {\n",
    "    \"City of London\",\n",
    "    \"Camden\",\n",
    "    \"Greenwich\",\n",
    "    \"Hackney\",\n",
    "    \"Hammersmith and Fulham\",\n",
    "    \"Islington\",\n",
    "    \"Kensington and Chelsea\",\n",
    "    \"Lambeth\",\n",
    "    \"Lewisham\",\n",
    "    \"Newham\",\n",
    "    \"Southwark\",\n",
    "    \"Tower Hamlets\",\n",
    "    \"Wandsworth\",\n",
    "    \"Westminster\",\n",
    "}\n",
    "\n",
    "def add_inner_outer(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"zone\"] = np.where(out[\"borough\"].isin(INNER_BOROUGHS), \"Inner London\", \"Outer London\")\n",
    "    return out\n",
    "\n",
    "# ---------------------------\n",
    "# Main analysis\n",
    "# ---------------------------\n",
    "def main() -> None:\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    ensure_geojson(BOROUGHS_GEOJSON, BOROUGHS_GEOJSON_URL)\n",
    "\n",
    "    # Load LAEI extracts\n",
    "    df_nox25, borough_cols = parse_sheet(INPUT_EXCEL, \"Nox Emission 2025\")\n",
    "    df_nox30, _ = parse_sheet(INPUT_EXCEL, \"Nox Emission 2030\")\n",
    "    df_pm25_25, _ = parse_sheet(INPUT_EXCEL, \"PM2.5 2025\")\n",
    "    df_pm25_30, _ = parse_sheet(INPUT_EXCEL, \"PM2.5 2030\")\n",
    "\n",
    "    # Extract sources\n",
    "    rt_nox25 = extract_borough_values(df_nox25, borough_cols, \"Road Transport\")\n",
    "    rt_nox30 = extract_borough_values(df_nox30, borough_cols, \"Road Transport\")\n",
    "    rt_pm25_25 = extract_borough_values(df_pm25_25, borough_cols, \"Road Transport\")\n",
    "    rt_pm25_30 = extract_borough_values(df_pm25_30, borough_cols, \"Road Transport\")\n",
    "    res_pm25_25 = extract_borough_values(df_pm25_25, borough_cols, \"Resuspension\")\n",
    "    res_pm25_30 = extract_borough_values(df_pm25_30, borough_cols, \"Resuspension\")\n",
    "\n",
    "    # Merge years + compute changes\n",
    "    m_rt_nox = merge_years(rt_nox25, rt_nox30, \"Road Transport NOx\")\n",
    "    m_rt_pm25 = merge_years(rt_pm25_25, rt_pm25_30, \"Road Transport PM2.5\")\n",
    "    m_res_pm25 = merge_years(res_pm25_25, res_pm25_30, \"Resuspension PM2.5\")\n",
    "\n",
    "    # London totals for scorecard\n",
    "    tot_rt_nox = totals(df_nox25, df_nox30, \"Road Transport\")\n",
    "    tot_rt_pm25 = totals(df_pm25_25, df_pm25_30, \"Road Transport\")\n",
    "    tot_res_pm25 = totals(df_pm25_25, df_pm25_30, \"Resuspension\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Figure 1 — Scorecard table\n",
    "    # ---------------------------\n",
    "    scorecard = pd.DataFrame(\n",
    "        [\n",
    "            [\"Road Transport NOx\", *tot_rt_nox],\n",
    "            [\"Road Transport PM2.5\", *tot_rt_pm25],\n",
    "            [\"Resuspension PM2.5\", *tot_res_pm25],\n",
    "        ],\n",
    "        columns=[\"Metric\", \"Total 2025\", \"Total 2030\", \"Absolute change\", \"% change\"],\n",
    "    )\n",
    "    scorecard_fmt = scorecard.copy()\n",
    "    scorecard_fmt[\"Total 2025\"] = scorecard_fmt[\"Total 2025\"].map(lambda x: f\"{x:,.1f}\")\n",
    "    scorecard_fmt[\"Total 2030\"] = scorecard_fmt[\"Total 2030\"].map(lambda x: f\"{x:,.1f}\")\n",
    "    scorecard_fmt[\"Absolute change\"] = scorecard_fmt[\"Absolute change\"].map(lambda x: f\"{x:,.1f}\")\n",
    "    scorecard_fmt[\"% change\"] = scorecard_fmt[\"% change\"].map(lambda x: f\"{x:.1f}%\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 2.2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axis(\"off\")\n",
    "    tbl = ax.table(\n",
    "        cellText=scorecard_fmt.values,\n",
    "        colLabels=scorecard_fmt.columns,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "    )\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(10)\n",
    "    tbl.scale(1, 1.5)\n",
    "    plt.title(\"Figure 1 — Headline changes (London total), 2025 → 2030\", pad=10)\n",
    "    fig1_path = os.path.join(OUT_DIR, \"fig1_scorecard.png\")\n",
    "    plt.savefig(fig1_path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Figure 3 — Top/Bottom 5 extremes (table)\n",
    "    # ---------------------------\n",
    "    def top_bottom(df: pd.DataFrame, n: int = 5):\n",
    "        s = df[[\"borough\", \"pct_change\"]].sort_values(\"pct_change\")\n",
    "        top = s.head(n).reset_index(drop=True)\n",
    "        bottom = s.tail(n).reset_index(drop=True)\n",
    "        return top, bottom\n",
    "\n",
    "    top_nox, bottom_nox = top_bottom(m_rt_nox, 5)\n",
    "    top_pm, bottom_pm = top_bottom(m_rt_pm25, 5)\n",
    "\n",
    "    tb = pd.DataFrame(\n",
    "        {\n",
    "            \"NOx — Top 5 (largest reductions)\": top_nox[\"borough\"],\n",
    "            \"NOx %Δ\": top_nox[\"pct_change\"].map(lambda x: f\"{x:.1f}%\"),\n",
    "            \"NOx — Bottom 5 (smallest reductions)\": bottom_nox[\"borough\"],\n",
    "            \"NOx %Δ \": bottom_nox[\"pct_change\"].map(lambda x: f\"{x:.1f}%\"),\n",
    "            \"PM2.5 — Top 5 (largest reductions)\": top_pm[\"borough\"],\n",
    "            \"PM2.5 %Δ\": top_pm[\"pct_change\"].map(lambda x: f\"{x:.1f}%\"),\n",
    "            \"PM2.5 — Bottom 5 (smallest reductions)\": bottom_pm[\"borough\"],\n",
    "            \"PM2.5 %Δ \": bottom_pm[\"pct_change\"].map(lambda x: f\"{x:.1f}%\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 2.8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axis(\"off\")\n",
    "    tbl = ax.table(\n",
    "        cellText=tb.values, colLabels=tb.columns, cellLoc=\"center\", loc=\"center\"\n",
    "    )\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(9)\n",
    "    tbl.scale(1, 1.5)\n",
    "    plt.title(\n",
    "        \"Figure 3 — Borough extremes in % change (Road Transport), 2025 → 2030\",\n",
    "        pad=10,\n",
    "    )\n",
    "    fig3_path = os.path.join(OUT_DIR, \"fig3_top_bottom5_table.png\")\n",
    "    plt.savefig(fig3_path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Figure 4 — Inner vs Outer (mean % change)\n",
    "    # ---------------------------\n",
    "    m_rt_nox_io = add_inner_outer(m_rt_nox)\n",
    "    m_rt_pm_io = add_inner_outer(m_rt_pm25)\n",
    "\n",
    "    means = pd.DataFrame(\n",
    "        {\n",
    "            \"Road Transport NOx\": m_rt_nox_io.groupby(\"zone\")[\"pct_change\"].mean(),\n",
    "            \"Road Transport PM2.5\": m_rt_pm_io.groupby(\"zone\")[\"pct_change\"].mean(),\n",
    "        }\n",
    "    ).loc[[\"Inner London\", \"Outer London\"]]\n",
    "\n",
    "    fig = plt.figure(figsize=(7.5, 4.8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    means.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_ylabel(\"Mean % change (2030 vs 2025)\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_title(\"Figure 4 — Inner vs Outer London (mean % change)\")\n",
    "    ax.axhline(0, linewidth=1)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    fig4_path = os.path.join(OUT_DIR, \"fig4_inner_outer_mean_pctchange.png\")\n",
    "    plt.savefig(fig4_path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Figure 5 — PM2.5 mechanism split (Road Transport vs Resuspension totals)\n",
    "    # ---------------------------\n",
    "    pm_mech = pd.DataFrame(\n",
    "        {\"2025\": [tot_rt_pm25[0], tot_res_pm25[0]], \"2030\": [tot_rt_pm25[1], tot_res_pm25[1]]},\n",
    "        index=[\"PM2.5 — Road Transport\", \"PM2.5 — Resuspension\"],\n",
    "    )\n",
    "\n",
    "    fig = plt.figure(figsize=(8.5, 4.8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    pm_mech.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_ylabel(\"Total emissions (tonnes/yr)\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_title(\"Figure 5 — PM2.5 pathways: tailpipe vs resuspension (London total)\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    fig5_path = os.path.join(OUT_DIR, \"fig5_pm25_mechanism_split.png\")\n",
    "    plt.savefig(fig5_path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Figure 2 — Interactive choropleths (HTML)\n",
    "    # ---------------------------\n",
    "    import plotly.express as px\n",
    "\n",
    "    with open(BOROUGHS_GEOJSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        gj = json.load(f)\n",
    "\n",
    "    map_nox2030 = m_rt_nox[[\"borough\", \"value_2030\"]].copy()\n",
    "    map_nox2030[\"borough_geo\"] = map_nox2030[\"borough\"].map(to_geo_name)\n",
    "\n",
    "    map_pm2030 = m_rt_pm25[[\"borough\", \"value_2030\"]].copy()\n",
    "    map_pm2030[\"borough_geo\"] = map_pm2030[\"borough\"].map(to_geo_name)\n",
    "\n",
    "    fig_nox = px.choropleth(\n",
    "        map_nox2030,\n",
    "        geojson=gj,\n",
    "        locations=\"borough_geo\",\n",
    "        featureidkey=\"properties.NAME\",\n",
    "        color=\"value_2030\",\n",
    "        projection=\"mercator\",\n",
    "        title=\"Figure 2a — Road Transport NOx (tonnes/yr), 2030\",\n",
    "    )\n",
    "    fig_nox.update_geos(fitbounds=\"locations\", visible=False)\n",
    "\n",
    "    fig_pm = px.choropleth(\n",
    "        map_pm2030,\n",
    "        geojson=gj,\n",
    "        locations=\"borough_geo\",\n",
    "        featureidkey=\"properties.NAME\",\n",
    "        color=\"value_2030\",\n",
    "        projection=\"mercator\",\n",
    "        title=\"Figure 2b — Road Transport PM2.5 (tonnes/yr), 2030\",\n",
    "    )\n",
    "    fig_pm.update_geos(fitbounds=\"locations\", visible=False)\n",
    "\n",
    "    fig2a_path = os.path.join(OUT_DIR, \"fig2a_map_nox_2030.html\")\n",
    "    fig2b_path = os.path.join(OUT_DIR, \"fig2b_map_pm25_2030.html\")\n",
    "    fig_nox.write_html(fig2a_path, include_plotlyjs=\"cdn\")\n",
    "    fig_pm.write_html(fig2b_path, include_plotlyjs=\"cdn\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # Export analysis-ready dataset (CSV) for GitHub / Data page\n",
    "    # ---------------------------\n",
    "    future_air_borough = (\n",
    "        m_rt_nox[[\"borough\", \"value_2025\", \"value_2030\", \"abs_change\", \"pct_change\"]]\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"value_2025\": \"nox_rt_2025\",\n",
    "                \"value_2030\": \"nox_rt_2030\",\n",
    "                \"abs_change\": \"nox_rt_abs\",\n",
    "                \"pct_change\": \"nox_rt_pct\",\n",
    "            }\n",
    "        )\n",
    "        .merge(\n",
    "            m_rt_pm25[[\"borough\", \"value_2025\", \"value_2030\", \"abs_change\", \"pct_change\"]].rename(\n",
    "                columns={\n",
    "                    \"value_2025\": \"pm25_rt_2025\",\n",
    "                    \"value_2030\": \"pm25_rt_2030\",\n",
    "                    \"abs_change\": \"pm25_rt_abs\",\n",
    "                    \"pct_change\": \"pm25_rt_pct\",\n",
    "                }\n",
    "            ),\n",
    "            on=\"borough\",\n",
    "        )\n",
    "        .merge(\n",
    "            m_res_pm25[[\"borough\", \"value_2025\", \"value_2030\", \"abs_change\", \"pct_change\"]].rename(\n",
    "                columns={\n",
    "                    \"value_2025\": \"pm25_res_2025\",\n",
    "                    \"value_2030\": \"pm25_res_2030\",\n",
    "                    \"abs_change\": \"pm25_res_abs\",\n",
    "                    \"pct_change\": \"pm25_res_pct\",\n",
    "                }\n",
    "            ),\n",
    "            on=\"borough\",\n",
    "        )\n",
    "    )\n",
    "    future_air_borough[\"zone\"] = np.where(\n",
    "        future_air_borough[\"borough\"].isin(INNER_BOROUGHS), \"Inner London\", \"Outer London\"\n",
    "    )\n",
    "\n",
    "    csv_path = os.path.join(OUT_DIR, \"future_air_borough_2025_2030_rt_resusp.csv\")\n",
    "    future_air_borough.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(\"[DONE] Outputs written to:\", OUT_DIR)\n",
    "    print(\" -\", os.path.basename(fig1_path))\n",
    "    print(\" -\", os.path.basename(fig2a_path))\n",
    "    print(\" -\", os.path.basename(fig2b_path))\n",
    "    print(\" -\", os.path.basename(fig3_path))\n",
    "    print(\" -\", os.path.basename(fig4_path))\n",
    "    print(\" -\", os.path.basename(fig5_path))\n",
    "    print(\" -\", os.path.basename(csv_path))\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
